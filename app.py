import streamlit as st
import zipfile
import tempfile
import os
import shutil
import io
import re
import random
import string
from openai import OpenAI
from langdetect import detect, LangDetectException
from collections import Counter

st.set_page_config(
    page_title="Rewriter + DUPLICATOR ‚Äî –†–µ—Ä–∞–π—Ç —Ç–µ–∫—Å—Ç—É + –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è",
    page_icon="üåêüîÑ",
    layout="wide"
)

# Session state
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'result' not in st.session_state:
    st.session_state.result = None

def generate_unique_site_names(theme, num=5):
    """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –Ω–∞–∑–≤ —Å–∞–π—Ç—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–µ–º–∏"""
    themes = {
        '–∑–¥–æ—Ä–æ–≤ —è': ['Vital', 'Health', 'Well', 'Pure', 'Balance', 'Life', 'Energy', 'Gesund'],
        '—Å–ø–æ—Ä—Ç': ['Sport', 'Fit', 'Active', 'Power', 'Gym', 'Run', 'Athlet', 'Train'],
        '–∫—Ä–∞—Å–∞': ['Beauty', 'Glow', 'Shine', 'Elegant', 'Charm', 'Style', 'Lux', 'Fashion'],
        '—ó–∂–∞': ['Food', 'Taste', 'Delicious', 'Gourmet', 'Kitchen', 'Recipe', 'Eat', 'Flavor'],
    }
    base_words = themes.get(theme.lower(), ['Site', 'Web', 'Net', 'Pro', 'Hub'])
    names = []
    for _ in range(num):
        word = random.choice(base_words)
        suffix = ''.join(random.choice(string.ascii_lowercase) for _ in range(random.randint(3, 6)))
        name = word + suffix.capitalize()
        names.append(name)
    return names

def detect_language(text: str) -> str:
    text_lower = text.lower()
    if len(text.strip()) < 50:
        return "de"

    # –£–ª—å—Ç—Ä–∞-–ø–æ—Å–∏–ª–µ–Ω–∞ –µ–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —ñ–Ω–¥–æ–Ω–µ–∑—ñ–π—Å—å–∫–æ—ó
    indonesian_strong = ["gizi", "ahli gizi", "pola makan", "sehari-hari", "seimbang", "kesehatan", "suplemen", "vitamin", "makanan", "diet", "hidup sehat"]
    indo_strong_count = sum(1 for word in indonesian_strong if word in text_lower)
    indonesian_weak = ["dalam", "untuk", "dan", "ini", "sangat", "penting", "pendekatan", "berbasis", "alami", "modern", "memandang", "sebagai", "bagian", "gaya hidup", "keseimbangan", "keteraturan", "pemilihan", "komponen", "sadar"]
    indo_weak_count = sum(1 for word in indonesian_weak if word in text_lower)
    if indo_strong_count >= 1 or (indo_strong_count + indo_weak_count >= 5):
        return "id"

    # –ù—ñ–º–µ—Ü—å–∫–∞
    if re.search(r'[√§√∂√º√Ñ√ñ√ú√ü]', text) or any(w in text_lower for w in ["gesund", "ern√§hrung", "wohlbefinden", "energie", "frauen", "m√§nner"]):
        return "de"

    # –†—É–º—É–Ω—Å—å–∫–∞
    if re.search(r'[ƒÉƒÇ√¢√Ç√Æ√é»ô»ò»õ»ö]', text) or any(w in text_lower for w in ["cum", "sƒÉ", "alegi", "vitaminele", "potrivite", "sfaturile", "nutri»õionistului", "pentru", "dietƒÉ", "echilibratƒÉ", "sƒÉnƒÉtate"]):
        return "ro"

    # –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞
    if any(w in text_lower for w in ["–∑–¥–æ—Ä–æ–≤", "–∑–¥–æ—Ä–æ–≤'—è", "–µ–Ω–µ—Ä–≥—ñ—è", "–∂—ñ–Ω–∫–∏", "—á–æ–ª–æ–≤—ñ–∫–∏", "–∂–∏—Ç—Ç—è", "–±–∞–ª–∞–Ω—Å"]):
        return "uk"

    # –†–æ—Å—ñ–π—Å—å–∫–∞
    if any(w in text_lower for w in ["–∑–¥–æ—Ä–æ–≤—å–µ", "–ø–∏—Ç–∞–Ω–∏–µ", "—ç–Ω–µ—Ä–≥–∏—è", "–∂–µ–Ω—â–∏–Ω—ã", "–º—É–∂—á–∏–Ω—ã", "–∂–∏–∑–Ω—å"]):
        return "ru"

    # –ê–Ω–≥–ª—ñ–π—Å—å–∫–∞
    if any(w in text_lower for w in ["health", "nutrition", "energy", "women", "men", "life"]):
        return "en"

    # –§—Ä–∞–Ω—Ü—É–∑—å–∫–∞
    if any(w in text_lower for w in ["sant√©", "nutrition", "√©nergie", "femmes", "hommes", "vie"]):
        return "fr"

    # –Ü—Å–ø–∞–Ω—Å—å–∫–∞
    if any(w in text_lower for w in ["salud", "nutrici√≥n", "energ√≠a", "mujeres", "hombres", "vida"]):
        return "es"

    # –Ü—Ç–∞–ª—ñ–π—Å—å–∫–∞
    if any(w in text_lower for w in ["salute", "nutrizione", "energia", "donne", "uomini", "vita"]):
        return "it"

    # –ü–æ–ª—å—Å—å–∫–∞
    if any(w in text_lower for w in ["zdrowie", "od≈ºywianie", "energia", "kobiety", "mƒô≈ºczy≈∫ni", "≈ºycie"]):
        return "pl"

    # –ù—ñ–¥–µ—Ä–ª–∞–Ω–¥—Å—å–∫–∞
    if any(w in text_lower for w in ["gezondheid", "voeding", "energie", "vrouwen", "mannen", "leven"]):
        return "nl"

    # –®–≤–µ–¥—Å—å–∫–∞
    if any(w in text_lower for w in ["h√§lsa", "n√§ring", "energi", "kvinnor", "m√§n", "liv"]):
        return "sv"

    # –ü–æ—Ä—Ç—É–≥–∞–ª—å—Å—å–∫–∞
    if any(w in text_lower for w in ["sa√∫de", "nutri√ß√£o", "energia", "mulheres", "homens", "vida"]):
        return "pt"

    # –°–ª–æ–≤–µ–Ω—Å—å–∫–∞
    if any(w in text_lower for w in ["zdravje", "prehrana", "energija", "≈æenske", "mo≈°ki", "≈æivljenje"]):
        return "sl"

    # –°–ª–æ–≤–∞—Ü—å–∫–∞
    if any(w in text_lower for w in ["zdravie", "v√Ω≈æiva", "energia", "≈æeny", "mu≈æi", "≈æivot"]):
        return "sk"

    # –ú–∞–ª–∞–π—Å—å–∫–∞
    if any(w in text_lower for w in ["kesihatan", "pemakanan", "tenaga", "wanita", "lelaki", "hidup"]):
        return "ms"

    # –Ü–Ω–¥—ñ–π—Å—å–∫–∞ (—Ö—ñ–Ω–¥—ñ)
    if re.search(r'[‡§π‡§ø‡§®‡•ç‡§¶‡•Ä]', text) or any(w in text_lower for w in ["‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø", "‡§™‡•ã‡§∑‡§£", "‡§ä‡§∞‡•ç‡§ú‡§æ", "‡§Æ‡§π‡§ø‡§≤‡§æ‡§è‡§Ç", "‡§™‡•Å‡§∞‡•Å‡§∑", "‡§ú‡•Ä‡§µ‡§®"]):
        return "hi"

    # –ß–µ—Å—å–∫–∞
    if any(w in text_lower for w in ["zdrav√≠", "v√Ω≈æiva", "energie", "≈æeny", "mu≈æi", "≈æivot"]):
        return "cs"

    # –£–≥–æ—Ä—Å—å–∫–∞
    if any(w in text_lower for w in ["eg√©szs√©g", "t√°pl√°lkoz√°s", "energia", "n≈ëk", "f√©rfiak", "√©let"]):
        return "hu"

    # –°–µ—Ä–±—Å—å–∫–∞
    if any(w in text_lower for w in ["–∑–¥—Ä–∞–≤—ô–µ", "–∏—Å—Ö—Ä–∞–Ω–∞", "–µ–Ω–µ—Ä–≥–∏—ò–∞", "–∂–µ–Ω–µ", "–º—É—à–∫–∞—Ä—Ü–∏", "–∂–∏–≤–æ—Ç"]):
        return "sr"

    # –ì—Ä–µ—Ü—å–∫–∞
    if re.search(r'[Œ±Œ≤Œ≥Œ¥ŒµŒ∂Œ∑Œ∏ŒπŒ∫ŒªŒºŒΩŒæŒøœÄœÅœÉœÑœÖœÜœáœàœâŒëŒíŒìŒîŒïŒñŒóŒòŒôŒöŒõŒúŒùŒûŒüŒ†Œ°Œ£Œ§Œ•Œ¶ŒßŒ®Œ©]', text) or any(w in text_lower for w in ["œÖŒ≥ŒµŒØŒ±", "Œ¥ŒπŒ±œÑœÅŒøœÜŒÆ", "ŒµŒΩŒ≠œÅŒ≥ŒµŒπŒ±", "Œ≥œÖŒΩŒ±ŒØŒ∫ŒµœÇ", "Œ¨ŒΩŒ¥œÅŒµœÇ", "Œ∂œâŒÆ"]):
        return "el"

    # –¢—É—Ä–µ—Ü—å–∫–∞
    if any(w in text_lower for w in ["saƒülƒ±k", "beslenme", "enerji", "kadƒ±nlar", "erkekler", "hayat"]):
        return "tr"

    # –ê—Ä–∞–±—Å—å–∫–∞
    if re.search(r'[ÿπÿ±ÿ®Ÿä]', text) or any(w in text_lower for w in ["ÿµÿ≠ÿ©", "ÿ™ÿ∫ÿ∞Ÿäÿ©", "ÿ∑ÿßŸÇÿ©", "ŸÜÿ≥ÿßÿ°", "ÿ±ÿ¨ÿßŸÑ", "ÿ≠Ÿäÿßÿ©"]):
        return "ar"

    try:
        lang = detect(text)
        if lang in ['id', 'ms']:
            return "id"
        return lang
    except LangDetectException:
        return "de"

def get_site_language(html_files: list) -> str:
    langs = []
    for path in html_files:
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            text = re.sub(r'<[^>]+>', ' ', content)[:15000]
            lang = detect_language(text)
            langs.append(lang)
        except:
            pass
    
    if not langs:
        return "de"

    most_common = Counter(langs).most_common(1)[0][0]
    lang_map = {
        'de': '–ù—ñ–º–µ—Ü—å–∫–∞',
        'uk': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞',
        'ru': '–†–æ—Å—ñ–π—Å—å–∫–∞',
        'en': '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞',
        'fr': '–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞',
        'es': '–Ü—Å–ø–∞–Ω—Å—å–∫–∞',
        'it': '–Ü—Ç–∞–ª—ñ–π—Å—å–∫–∞',
        'pl': '–ü–æ–ª—å—Å—å–∫–∞',
        'nl': '–ù—ñ–¥–µ—Ä–ª–∞–Ω–¥—Å—å–∫–∞',
        'sv': '–®–≤–µ–¥—Å—å–∫–∞',
        'pt': '–ü–æ—Ä—Ç—É–≥–∞–ª—å—Å—å–∫–∞',
        'ro': '–†—É–º—É–Ω—Å—å–∫–∞',
        'sl': '–°–ª–æ–≤–µ–Ω—Å—å–∫–∞',
        'sk': '–°–ª–æ–≤–∞—Ü—å–∫–∞',
        'id': '–Ü–Ω–¥–æ–Ω–µ–∑—ñ–π—Å—å–∫–∞',
        'ms': '–ú–∞–ª–∞–π—Å—å–∫–∞',
        'hi': '–Ü–Ω–¥—ñ–π—Å—å–∫–∞ (—Ö—ñ–Ω–¥—ñ)',
        'cs': '–ß–µ—Å—å–∫–∞',
        'hu': '–£–≥–æ—Ä—Å—å–∫–∞',
        'sr': '–°–µ—Ä–±—Å—å–∫–∞',
        'el': '–ì—Ä–µ—Ü—å–∫–∞',
        'tr': '–¢—É—Ä–µ—Ü—å–∫–∞',
        'ar': '–ê—Ä–∞–±—Å—å–∫–∞',
    }
    return lang_map.get(most_common, "–ù—ñ–º–µ—Ü—å–∫–∞")

lang_to_countries = {
    '–ù—ñ–º–µ—Ü—å–∫–∞': ['–ù—ñ–º–µ—á—á–∏–Ω–∞', '–ê–≤—Å—Ç—Ä—ñ—è', '–®–≤–µ–π—Ü–∞—Ä—ñ—è'],
    '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞': ['–£–∫—Ä–∞—ó–Ω–∞'],
    '–†–æ—Å—ñ–π—Å—å–∫–∞': ['–†–æ—Å—ñ—è', '–ë—ñ–ª–æ—Ä—É—Å—å', '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω'],
    '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞': ['–°–®–ê', '–í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω—ñ—è', '–ê–≤—Å—Ç—Ä–∞–ª—ñ—è', '–ö–∞–Ω–∞–¥–∞', '–Ü—Ä–ª–∞–Ω–¥—ñ—è'],
    '–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞': ['–§—Ä–∞–Ω—Ü—ñ—è', '–ö–∞–Ω–∞–¥–∞', '–ë–µ–ª—å–≥—ñ—è', '–®–≤–µ–π—Ü–∞—Ä—ñ—è'],
    '–Ü—Å–ø–∞–Ω—Å—å–∫–∞': ['–Ü—Å–ø–∞–Ω—ñ—è', '–ú–µ–∫—Å–∏–∫–∞', '–ê—Ä–≥–µ–Ω—Ç–∏–Ω–∞', '–ö–æ–ª—É–º–±—ñ—è'],
    '–Ü—Ç–∞–ª—ñ–π—Å—å–∫–∞': ['–Ü—Ç–∞–ª—ñ—è', '–®–≤–µ–π—Ü–∞—Ä—ñ—è'],
    '–ü–æ–ª—å—Å—å–∫–∞': ['–ü–æ–ª—å—â–∞'],
    '–ù—ñ–¥–µ—Ä–ª–∞–Ω–¥—Å—å–∫–∞': ['–ù—ñ–¥–µ—Ä–ª–∞–Ω–¥–∏', '–ë–µ–ª—å–≥—ñ—è'],
    '–®–≤–µ–¥—Å—å–∫–∞': ['–®–≤–µ—Ü—ñ—è', '–§—ñ–Ω–ª—è–Ω–¥—ñ—è'],
    '–ü–æ—Ä—Ç—É–≥–∞–ª—å—Å—å–∫–∞': ['–ü–æ—Ä—Ç—É–≥–∞–ª—ñ—è', '–ë—Ä–∞–∑–∏–ª—ñ—è'],
    '–†—É–º—É–Ω—Å—å–∫–∞': ['–†—É–º—É–Ω—ñ—è', '–ú–æ–ª–¥–æ–≤–∞'],
    '–°–ª–æ–≤–µ–Ω—Å—å–∫–∞': ['–°–ª–æ–≤–µ–Ω—ñ—è'],
    '–°–ª–æ–≤–∞—Ü—å–∫–∞': ['–°–ª–æ–≤–∞—á—á–∏–Ω–∞'],
    '–Ü–Ω–¥–æ–Ω–µ–∑—ñ–π—Å—å–∫–∞': ['–Ü–Ω–¥–æ–Ω–µ–∑—ñ—è'],
    '–ú–∞–ª–∞–π—Å—å–∫–∞': ['–ú–∞–ª–∞–π–∑—ñ—è', '–ë—Ä—É–Ω–µ–π', '–°—ñ–Ω–≥–∞–ø—É—Ä'],
    '–Ü–Ω–¥—ñ–π—Å—å–∫–∞ (—Ö—ñ–Ω–¥—ñ)': ['–Ü–Ω–¥—ñ—è'],
    '–ß–µ—Å—å–∫–∞': ['–ß–µ—Ö—ñ—è'],
    '–£–≥–æ—Ä—Å—å–∫–∞': ['–£–≥–æ—Ä—â–∏–Ω–∞'],
    '–°–µ—Ä–±—Å—å–∫–∞': ['–°–µ—Ä–±—ñ—è', '–ß–æ—Ä–Ω–æ–≥–æ—Ä—ñ—è', '–ë–æ—Å–Ω—ñ—è —ñ –ì–µ—Ä—Ü–µ–≥–æ–≤–∏–Ω–∞'],
    '–ì—Ä–µ—Ü—å–∫–∞': ['–ì—Ä–µ—Ü—ñ—è', '–ö—ñ–ø—Ä'],
    '–¢—É—Ä–µ—Ü—å–∫–∞': ['–¢—É—Ä–µ—á—á–∏–Ω–∞'],
    '–ê—Ä–∞–±—Å—å–∫–∞': ['–Ñ–≥–∏–ø–µ—Ç', '–°–∞—É–¥—ñ–≤—Å—å–∫–∞ –ê—Ä–∞–≤—ñ—è', '–û–±‚Äô—î–¥–Ω–∞–Ω—ñ –ê—Ä–∞–±—Å—å–∫—ñ –ï–º—ñ—Ä–∞—Ç–∏', '–ú–∞—Ä–æ–∫–∫–æ', '–ê–ª–∂–∏—Ä'],
}

lang_to_phone = {
    '–ù—ñ–º–µ—Ü—å–∫–∞': '+49',
    '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞': '+380',
    '–†–æ—Å—ñ–π—Å—å–∫–∞': '+7',
    '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞': '+44',
    '–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞': '+33',
    '–Ü—Å–ø–∞–Ω—Å—å–∫–∞': '+34',
    '–Ü—Ç–∞–ª—ñ–π—Å—å–∫–∞': '+39',
    '–ü–æ–ª—å—Å—å–∫–∞': '+48',
    '–ù—ñ–¥–µ—Ä–ª–∞–Ω–¥—Å—å–∫–∞': '+31',
    '–®–≤–µ–¥—Å—å–∫–∞': '+46',
    '–ü–æ—Ä—Ç—É–≥–∞–ª—å—Å—å–∫–∞': '+351',
    '–†—É–º—É–Ω—Å—å–∫–∞': '+40',
    '–°–ª–æ–≤–µ–Ω—Å—å–∫–∞': '+386',
    '–°–ª–æ–≤–∞—Ü—å–∫–∞': '+421',
    '–Ü–Ω–¥–æ–Ω–µ–∑—ñ–π—Å—å–∫–∞': '+62',
    '–ú–∞–ª–∞–π—Å—å–∫–∞': '+60',
    '–Ü–Ω–¥—ñ–π—Å—å–∫–∞ (—Ö—ñ–Ω–¥—ñ)': '+91',
    '–ß–µ—Å—å–∫–∞': '+420',
    '–£–≥–æ—Ä—Å—å–∫–∞': '+36',
    '–°–µ—Ä–±—Å—å–∫–∞': '+381',
    '–ì—Ä–µ—Ü—å–∫–∞': '+30',
    '–¢—É—Ä–µ—Ü—å–∫–∞': '+90',
    '–ê—Ä–∞–±—Å—å–∫–∞': '+20',
}

def rewrite_content(client, original_html: str, language: str, new_site_name: str) -> str:
    if language not in lang_to_countries:
        st.error(f"–ú–æ–≤–∞ '{language}' –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è.")
        return original_html

    country = random.choice(lang_to_countries[language])
    phone_prefix = lang_to_phone.get(language, '+1')

    prompt = f"""
–¢–Ü–õ–¨–ö–ò —Ä–µ—Ñ—Ä–∞–∑—É–π –≤–∏–¥–∏–º–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ –º–æ–≤—ñ '{language}' ‚Äî –∑—Ä–æ–±–∏ –π–æ–≥–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º, –ø—Ä–∏—Ä–æ–¥–Ω–∏–º, –ø—Ä–∏–≤–∞–±–ª–∏–≤–∏–º.
–ó–ê–ë–û–†–û–ù–ï–ù–û –±—É–¥—å-—è–∫—ñ –∑–º—ñ–Ω–∏ –∫—Ä—ñ–º —Ç–µ–∫—Å—Ç—É:
- –ù–ï –∑–º—ñ–Ω—é–≤–∞—Ç–∏ —Ç–µ–≥–∏, –∞—Ç—Ä–∏–±—É—Ç–∏, –∫–ª–∞—Å–∏, id, name, value, placeholder, action, method, onclick, src, href
- –ù–ï –ª–∞–º–∞—Ç–∏ —Ñ–æ—Ä–º–∏, input, button, select, textarea, —Å–∫—Ä–∏–ø—Ç–∏, —Å—Ç–∏–ª—ñ, –ø–æ—Å–∏–ª–∞–Ω–Ω—è, –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- –ù–ï –¥–æ–¥–∞–≤–∞—Ç–∏/–≤–∏–¥–∞–ª—è—Ç–∏ –µ–ª–µ–º–µ–Ω—Ç–∏
- –ù–ï –∑–º—ñ–Ω—é–≤–∞—Ç–∏ JS-–∫–æ–¥, –ø–æ–¥—ñ—ó, —Å—Ç—Ä—É–∫—Ç—É—Ä—É
–ó–∞–º—ñ–Ω—é–π –¢–Ü–õ–¨–ö–ò —á–∏—Å—Ç–∏–π —Ç–µ–∫—Å—Ç –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ —Ç–µ–≥—ñ–≤ (h1-h6, p, li, span, div –∑ —Ç–µ–∫—Å—Ç–æ–º, label, option —Ç–æ—â–æ).
–ó–∞–º—ñ–Ω–∏ –Ω–∞–∑–≤—É —Å–∞–π—Ç—É –Ω–∞ '{new_site_name}' –≤—Å—é–¥–∏, –¥–µ –≤–æ–Ω–∞ –∑–≥–∞–¥—É—î—Ç—å—Å—è –≤ —Ç–µ–∫—Å—Ç—ñ.
–ö–æ–Ω—Ç–∞–∫—Ç–∏ (–∞–¥—Ä–µ—Å–∞, —Ç–µ–ª–µ—Ñ–æ–Ω) ‚Äî –∑–∞–º—ñ–Ω–∏ –Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤—ñ –ø—Ä–∞–≤–¥–æ–ø–æ–¥—ñ–±–Ω—ñ (–∞–¥—Ä–µ—Å–∞ –≤ {country}, –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω—É {phone_prefix}...).
–Ø–∫—â–æ –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤ –Ω–µ –±—É–ª–æ ‚Äî –Ω–µ –¥–æ–¥–∞–≤–∞–π —ó—Ö.
–ü–æ–≤–µ—Ä—Ç–∞–π –¢–Ü–õ–¨–ö–ò –ø–æ–≤–Ω–∏–π HTML/PHP –∑ –∑–∞–º—ñ–Ω–µ–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω—å.
–û—Ä–∏–≥—ñ–Ω–∞–ª:
{original_html}
"""

    try:
        resp = client.chat.completions.create(
            model="grok-code-fast-1",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=8192,
            timeout=600
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"–ü–æ–º–∏–ª–∫–∞ —Ä–µ—Ä–∞–π—Ç—É: {str(e)}. –ó–∞–ª–∏—à–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª.")
        return original_html

st.title("üåê Rewriter + DUPLICATOR ‚Äî –†–µ—Ä–∞–π—Ç —Ç–µ–∫—Å—Ç—É + –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è")

with st.expander("‚ÑπÔ∏è –Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏", expanded=True):
    st.markdown("""
    1. –í–≤–µ–¥–∏ xAI API Key  
    2. –í–≤–µ–¥–∏ —Ç–µ–º—É —Å–∞–π—Ç—É (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –Ω–∞–∑–≤, –Ω–∞–ø—Ä. '–∑–¥–æ—Ä–æ–≤ —è')
    3. –ó–∞–≤–∞–Ω—Ç–∞–∂ ZIP/RAR –∞—Ä—Ö—ñ–≤(–∏) —Å–∞–π—Ç—É  
    4. –û–±–µ—Ä–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ø—ñ–π —ñ –¥–æ–º–µ–Ω–Ω—É –∑–æ–Ω—É  
    5. –ù–∞—Ç–∏—Å–Ω–∏ –∫–Ω–æ–ø–∫—É ‚Äî –æ—Ç—Ä–∏–º–∞–π –∞—Ä—Ö—ñ–≤ –∑ 5 —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º–∏ –≤–∞—Ä—ñ–∞–Ω—Ç–∞–º–∏ (–∫–æ–∂–µ–Ω –∑ —Ä–µ—Ä–∞–π—Ç–æ–º, –Ω–æ–≤–æ—é –Ω–∞–∑–≤–æ—é —ñ –¥–æ–º–µ–Ω–æ–º)
    """)

api_key = st.text_input("xAI API Key", type="password")
theme = st.text_input("–¢–µ–º–∞ —Å–∞–π—Ç—É (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –Ω–∞–∑–≤)", value="–∑–¥–æ—Ä–æ–≤ —è")

col1, col2 = st.columns([2, 1])

with col1:
    uploaded_files = st.file_uploader(
        "–ê—Ä—Ö—ñ–≤–∏ —Å–∞–π—Ç—ñ–≤ (ZIP/RAR)",
        type=['zip', 'rar'],
        accept_multiple_files=True
    )

with col2:
    domain_zone = st.radio("–î–æ–º–µ–Ω–Ω–∞ –∑–æ–Ω–∞:", ['.com', '.info'], horizontal=True)
    copies_count = st.number_input("–ö–æ–ø—ñ–π –Ω–∞ –∞—Ä—Ö—ñ–≤:", min_value=1, max_value=5, value=5)

if uploaded_files and api_key and theme:
    if st.button("üöÄ –°—Ç–≤–æ—Ä–∏—Ç–∏ 5 —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∫–æ–ø—ñ–π –∑ —Ä–µ—Ä–∞–π—Ç–æ–º", type="primary"):
        client = OpenAI(api_key=api_key, base_url="https://api.x.ai/v1", timeout=600)

        temp_input = tempfile.mkdtemp()
        temp_rewritten = tempfile.mkdtemp()
        temp_clones = tempfile.mkdtemp()

        progress = st.progress(0)
        status = st.empty()

        # 1. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞—Ä—Ö—ñ–≤—ñ–≤
        status.text("–ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞—Ä—Ö—ñ–≤–∏...")
        archive_paths = []
        for i, f in enumerate(uploaded_files):
            path = os.path.join(temp_input, f.name)
            with open(path, 'wb') as out:
                out.write(f.getbuffer())
            archive_paths.append(path)
            progress.progress((i+1)/len(uploaded_files) * 0.1)

        # –ì–µ–Ω–µ—Ä—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –Ω–∞–∑–≤–∏
        unique_names = generate_unique_site_names(theme, copies_count * len(archive_paths))
        name_index = 0

        # 2. –†–µ—Ä–∞–π—Ç —ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏
        status.text("–†–µ—Ä–∞–π—Ç —ñ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤...")
        master_zip_path = os.path.join(temp_clones, "duplicates.zip")
        with zipfile.ZipFile(master_zip_path, 'w', zipfile.ZIP_DEFLATED) as master_zip:
            for var_num in range(1, copies_count + 1):
                status.text(f"–í–∞—Ä—ñ–∞–Ω—Ç {var_num} –∑ {copies_count}...")
                for arch_idx, arch in enumerate(archive_paths):
                    extract_dir = os.path.join(temp_rewritten, f"var_{var_num}_arch_{arch_idx}")
                    os.makedirs(extract_dir, exist_ok=True)
                    try:
                        with zipfile.ZipFile(arch, 'r') as z:
                            z.extractall(extract_dir)
                    except:
                        st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞–∫—É–≤–∞—Ç–∏ {os.path.basename(arch)}")
                        continue

                    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ .html, .htm —Ç–∞ .php —Ñ–∞–π–ª–∏ –¥–ª—è —Ä–µ—Ä–∞–π—Ç—É
                    text_files = [os.path.join(root, f) for root, _, fs in os.walk(extract_dir) for f in fs if f.lower().endswith(('.html', '.htm', '.php'))]

                    lang = get_site_language(text_files)
                    st.info(f"–ú–æ–≤–∞ –¥–ª—è –≤–∞—Ä—ñ–∞–Ω—Ç–∞ {var_num} –∞—Ä—Ö—ñ–≤—É {os.path.basename(arch)}: {lang}")

                    new_site_name = unique_names[name_index]
                    name_index += 1

                    rewritten_count = 0
                    for file_path in text_files:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                        new_content = rewrite_content(client, content, lang, new_site_name)
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        rewritten_count += 1

                    # –î–æ–¥–∞—î–º–æ –≤ –≥–æ–ª–æ–≤–Ω–∏–π –∞—Ä—Ö—ñ–≤ –í–°–Ü —Ñ–∞–π–ª–∏ (–≤–∫–ª—é—á–∞—é—á–∏ –Ω–µ-html/php)
                    for root, _, files in os.walk(extract_dir):
                        for file in files:
                            full = os.path.join(root, file)
                            arc = os.path.relpath(full, temp_rewritten)
                            master_zip.write(full, arc)

                    st.info(f"–í–∞—Ä—ñ–∞–Ω—Ç {var_num} –∞—Ä—Ö—ñ–≤—É {arch_idx} –≥–æ—Ç–æ–≤–∏–π: {rewritten_count} —Ñ–∞–π–ª—ñ–≤ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–æ, –Ω–æ–≤–∞ –Ω–∞–∑–≤–∞ {new_site_name}")

                    progress.progress(0.1 + (var_num * (arch_idx+1)) / (copies_count * len(archive_paths)) * 0.9)

        st.session_state.result = {'success': True, 'master_archive_path': master_zip_path}
        st.session_state.processed = True
        st.rerun()

else:
    st.warning("–í–≤–µ–¥–∏ –∫–ª—é—á, —Ç–µ–º—É —ñ –∑–∞–≤–∞–Ω—Ç–∞–∂ –∞—Ä—Ö—ñ–≤–∏")

if st.session_state.processed and st.session_state.result:
    st.success("–ì–æ—Ç–æ–≤–æ! 5 —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –∑ —Ä–µ—Ä–∞–π—Ç–æ–º —ñ –Ω–∞–∑–≤–∞–º–∏.")
    with open(st.session_state.result['master_archive_path'], 'rb') as f:
        data = f.read()
    st.download_button(
        label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç–∏ –≥–æ–ª–æ–≤–Ω–∏–π –∞—Ä—Ö—ñ–≤ (–≤—Å—ñ 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤)",
        data=data,
        file_name="unique_rewritten_duplicates.zip",
        mime="application/zip"
    )
