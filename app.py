import streamlit as st
import zipfile
import tempfile
import os
import shutil
import io
import re
from openai import OpenAI
from langdetect import detect, DetectorFactory
from langdetect.lang_detect_exception import LangDetectException
from collections import Counter

# –§—ñ–∫—Å—É—î–º–æ seed –¥–ª—è langdetect, —â–æ–± —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±—É–ª–∏ –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω—ñ
DetectorFactory.seed = 0

st.set_page_config(
    page_title="Rewriter + DUPLICATOR - –†–µ—Ä–∞–π—Ç + –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è —Å–∞–π—Ç—ñ–≤",
    page_icon="üåêüîÑ",
    layout="wide"
)

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è session state
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'result' not in st.session_state:
    st.session_state.result = None

def detect_site_language(html_content: str) -> str:
    """–í–∏–∑–Ω–∞—á–∞—î –º–æ–≤—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑–∞ —Ç–µ–∫—Å—Ç–æ–º"""
    try:
        # –ë–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–µ–≥—ñ–≤
        text = re.sub(r'<[^>]+>', ' ', html_content)
        text = re.sub(r'\s+', ' ', text).strip()
        if len(text) < 50:
            return "unknown"
        lang = detect(text)
        # –ú–∞–ø–∏–º–æ –Ω–∞ –∑—Ä–æ–∑—É–º—ñ–ª—ñ –Ω–∞–∑–≤–∏
        lang_map = {
            'uk': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞',
            'ru': '–†–æ—Å—ñ–π—Å—å–∫–∞',
            'en': '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞',
            'fr': '–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞',
            'de': '–ù—ñ–º–µ—Ü—å–∫–∞',
            'pl': '–ü–æ–ª—å—Å—å–∫–∞',
            # –¥–æ–¥–∞–π —ñ–Ω—à—ñ –∑–∞ –ø–æ—Ç—Ä–µ–±–æ—é
        }
        return lang_map.get(lang, lang.upper())
    except LangDetectException:
        return "unknown"

def get_dominant_language(html_files: list) -> str:
    """–í–∏–∑–Ω–∞—á–∞—î –¥–æ–º—ñ–Ω—É—é—á—É –º–æ–≤—É —Å–∞–π—Ç—É –ø–æ –≤—Å—ñ—Ö HTML"""
    languages = []
    for html_path in html_files:
        try:
            with open(html_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            lang = detect_site_language(content)
            if lang != "unknown":
                languages.append(lang)
        except:
            pass
    
    if not languages:
        return "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"  # –¥–µ—Ñ–æ–ª—Ç
    
    # –ù–∞–π–ø–æ—à–∏—Ä–µ–Ω—ñ—à–∞ –º–æ–≤–∞
    most_common = Counter(languages).most_common(1)
    return most_common[0][0] if most_common else "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"

def rewrite_html_with_grok(client, html_content: str, language: str, business_name: str) -> str:
    """–†–µ—Ä–∞–π—Ç –æ–¥–Ω—ñ—î—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —á–µ—Ä–µ–∑ Grok"""
    prompt = f"""
–ü–µ—Ä–µ–ø–∏—à–∏ –≤–µ—Å—å –≤–∏–¥–∏–º–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ –Ω–∞ –º–æ–≤—ñ '{language}' ‚Äî –∑—Ä–æ–±–∏ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º, –ø—Ä–∏—Ä–æ–¥–Ω–∏–º, –ø—Ä–∏–≤–∞–±–ª–∏–≤–∏–º.
–ó–±–µ—Ä—ñ–≥–∞–π 100% HTML-—Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Ç–µ–≥–∏, –∞—Ç—Ä–∏–±—É—Ç–∏, —Å–∫—Ä–∏–ø—Ç–∏, —Å—Ç–∏–ª—ñ, –ø–æ—Å–∏–ª–∞–Ω–Ω—è, –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –Ω—ñ—á–æ–≥–æ –Ω–µ –≤–∏–¥–∞–ª—è–π —ñ –Ω–µ –¥–æ–¥–∞–≤–∞–π.
–î–ª—è –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤ (–∞–¥—Ä–µ—Å–∞, —Ç–µ–ª–µ—Ñ–æ–Ω, –ª–æ–∫–∞—Ü—ñ—è) ‚Äî –∑–∞–º—ñ–Ω–∏ –Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤—ñ –ø—Ä–∞–≤–¥–æ–ø–æ–¥—ñ–±–Ω—ñ –¥–∞–Ω—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –±—ñ–∑–Ω–µ—Å—É '{business_name}' 
(–∞–¥—Ä–µ—Å–∞ –≤ –£–∫—Ä–∞—ó–Ω—ñ, –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω—É +380...).
–ü–æ–≤–µ—Ä—Ç–∞–π –¢–Ü–õ–¨–ö–ò —á–∏—Å—Ç–∏–π HTML-–∫–æ–¥, –±–µ–∑ –∂–æ–¥–Ω–∏—Ö –ø–æ—è—Å–Ω–µ–Ω—å —á–∏ –º–∞—Ä–∫–¥–∞—É–Ω—É.
–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π HTML:
{html_content}
"""

    try:
        resp = client.chat.completions.create(
            model="grok-4-1-fast-reasoning",  # —à–≤–∏–¥–∫–∞ –º–æ–¥–µ–ª—å
            messages=[
                {"role": "system", "content": "–ï–∫—Å–ø–µ—Ä—Ç –∑ —Ä–µ—Ä–∞–π—Ç—É –≤–µ–±-–∫–æ–Ω—Ç–µ–Ω—Ç—É."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4096,
            timeout=300
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ —Ä–µ—Ä–∞–π—Ç—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏: {str(e)}")
        return html_content  # –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª, —è–∫—â–æ –ø–æ–º–∏–ª–∫–∞

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –û—Å–Ω–æ–≤–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å (–∑–±–µ—Ä–µ–∂–µ–Ω–æ –∑ DUPLICATOR)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

st.title("üåê Rewriter + DUPLICATOR ‚Äî –†–µ—Ä–∞–π—Ç + –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è —Å–∞–π—Ç—ñ–≤")

with st.expander("‚ÑπÔ∏è –Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏", expanded=True):
    st.markdown("""
    1. –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ ZIP/RAR –∞—Ä—Ö—ñ–≤(–∏) –∑ —Å–∞–π—Ç–æ–º
    2. –í–∫–∞–∂—ñ—Ç—å API-–∫–ª—é—á xAI —Ç–∞ –Ω–∞–∑–≤—É –±—ñ–∑–Ω–µ—Å—É (–¥–ª—è –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤)
    3. –û–±–µ—Ä—ñ—Ç—å –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ø—ñ–π —ñ –¥–æ–º–µ–Ω–Ω—É –∑–æ–Ω—É
    4. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å "–°—Ç–≤–æ—Ä–∏—Ç–∏ –∫–æ–ø—ñ—ó –∑ —Ä–µ—Ä–∞–π—Ç–æ–º"
    """)

api_key = st.text_input("xAI API Key", type="password")
business_name = st.text_input("–ù–∞–∑–≤–∞ –±—ñ–∑–Ω–µ—Å—É (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤)")

col1, col2 = st.columns([2, 1])

with col1:
    uploaded_files = st.file_uploader(
        "–ê—Ä—Ö—ñ–≤–∏ —Å–∞–π—Ç—ñ–≤ (ZIP/RAR)",
        type=['zip', 'rar'],
        accept_multiple_files=True
    )

with col2:
    domain_zone = st.radio("–î–æ–º–µ–Ω–Ω–∞ –∑–æ–Ω–∞:", ['.com', '.info'], horizontal=True)
    copies_count = st.number_input("–ö–æ–ø—ñ–π –Ω–∞ –∞—Ä—Ö—ñ–≤:", min_value=1, max_value=50, value=5)

if uploaded_files and api_key and business_name:
    if st.button("üöÄ –°—Ç–≤–æ—Ä–∏—Ç–∏ –∫–æ–ø—ñ—ó –∑ —Ä–µ—Ä–∞–π—Ç–æ–º", type="primary"):
        if not api_key.startswith("xai-"):
            st.error("–ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç API-–∫–ª—é—á–∞. –ü–æ–≤–∏–Ω–µ–Ω –ø–æ—á–∏–Ω–∞—Ç–∏—Å—è –∑ 'xai-'")
            st.stop()

        client = OpenAI(api_key=api_key, base_url="https://api.x.ai/v1", timeout=300)

        temp_input = tempfile.mkdtemp()
        temp_output = tempfile.mkdtemp()
        temp_rewritten = tempfile.mkdtemp()

        progress = st.progress(0)
        status = st.empty()

        # –ö—Ä–æ–∫ 1: –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤
        status.text("–ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞—Ä—Ö—ñ–≤–∏...")
        archive_paths = []
        for i, f in enumerate(uploaded_files):
            path = os.path.join(temp_input, f.name)
            with open(path, 'wb') as out:
                out.write(f.getbuffer())
            archive_paths.append(path)
            progress.progress((i+1)/len(uploaded_files) * 0.1)

        # –ö—Ä–æ–∫ 2: —Ä–æ–∑–ø–∞–∫–æ–≤–∫–∞ —Ç–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤–∏
        status.text("–†–æ–∑–ø–∞–∫–æ–≤—É—î–º–æ —Ç–∞ –≤–∏–∑–Ω–∞—á–∞—î–º–æ –º–æ–≤—É —Å–∞–π—Ç—É...")
        all_html_files = []
        for arch in archive_paths:
            extract_dir = os.path.join(temp_rewritten, os.path.basename(arch).replace('.zip','').replace('.rar',''))
            os.makedirs(extract_dir, exist_ok=True)
            with zipfile.ZipFile(arch, 'r') as z:  # –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ rar –ø—ñ–¥—Ç—Ä–∏–º–∫—É —á–µ—Ä–µ–∑ rarfile
                z.extractall(extract_dir)
            htmls = [os.path.join(root, f) for root, _, fs in os.walk(extract_dir) for f in fs if f.lower().endswith('.html')]
            all_html_files.extend(htmls)

        if all_html_files:
            detected_lang = get_dominant_language(all_html_files)
            st.success(f"–í–∏–∑–Ω–∞—á–µ–Ω–æ –º–æ–≤—É —Å–∞–π—Ç—É: **{detected_lang}**")
        else:
            detected_lang = "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"
            st.warning("–ú–æ–≤—É –Ω–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–∑–Ω–∞—á–∏—Ç–∏ ‚Üí –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –£–∫—Ä–∞—ó–Ω—Å—å–∫—É")

        # –ö—Ä–æ–∫ 3: —Ä–µ—Ä–∞–π—Ç —Ç–µ–∫—Å—Ç—É
        status.text("–†–µ—Ä–∞–π—Ç —Ç–µ–∫—Å—Ç—É –Ω–∞ –≤–∏—è–≤–ª–µ–Ω—ñ–π –º–æ–≤—ñ...")
        rewritten_count = 0
        for html_path in all_html_files:
            try:
                with open(html_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                new_content = rewrite_html_with_grok(client, content, detected_lang, business_name)
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                rewritten_count += 1
            except:
                pass

        st.info(f"–ü–µ—Ä–µ–ø–∏—Å–∞–Ω–æ {rewritten_count} —Å—Ç–æ—Ä—ñ–Ω–æ–∫")

        # –ö—Ä–æ–∫ 4: –∫–ª–æ–Ω—É–≤–∞–Ω–Ω—è –∑ –∑–∞–º—ñ–Ω–æ—é –¥–æ–º–µ–Ω—ñ–≤ (—Ç—É—Ç —Ç—Ä–µ–±–∞ —Ç–≤—ñ–π BatchProcessor)
        # –Ø–∫—â–æ —É —Ç–µ–±–µ —î utils.batch_processor ‚Äî —ñ–º–ø–æ—Ä—Ç—É–π —ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π
        # –î–ª—è –ø—Ä–∏–∫–ª–∞–¥—É ‚Äî –ø—Ä–æ—Å—Ç–æ —ñ–º—ñ—Ç—É—î–º–æ (–∑–∞–º—ñ–Ω–∏ –Ω–∞ —Å–≤—ñ–π –∫–æ–¥)
        status.text("–°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–ø—ñ—ó –∑ –Ω–æ–≤–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏...")
        # processor = BatchProcessor()
        # result = processor.process_multiple_archives(
        #     archives=[temp_rewritten],  # –≤–∂–µ –∑ —Ä–µ—Ä–∞–π—Ç–æ–º
        #     copies_count=copies_count,
        #     domain_zone=domain_zone,
        #     output_dir=temp_output
        # )

        # –¢–∏–º—á–∞—Å–æ–≤–æ ‚Äî –ø—Ä–æ—Å—Ç–æ –∫–æ–ø—ñ—é—î–º–æ —è–∫ –ø—Ä–∏–∫–ª–∞–¥
        result = {
            'success': True,
            'master_archive_path': os.path.join(temp_output, "master.zip")
        }

        # –ö—Ä–æ–∫ 5: —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥–æ–ª–æ–≤–Ω–æ–≥–æ –∞—Ä—Ö—ñ–≤—É (—Ç—É—Ç —Ç–≤—ñ–π –∫–æ–¥)
        # ...

        st.session_state.result = result
        st.session_state.processed = True
        st.rerun()

else:
    st.warning("–ó–∞–ø–æ–≤–Ω—ñ—Ç—å —É—Å—ñ –ø–æ–ª—è: API-–∫–ª—é—á, –±—ñ–∑–Ω–µ—Å, –∞—Ä—Ö—ñ–≤–∏")

if st.session_state.processed and st.session_state.result:
    st.success("–ì–æ—Ç–æ–≤–æ!")
    # –¢—É—Ç –∫–Ω–æ–ø–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ result['master_archive_path']
