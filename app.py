import streamlit as st
import zipfile
import tempfile
import os
import shutil
import io
import re
from openai import OpenAI
import fasttext
from langdetect import detect, LangDetectException
from collections import Counter

st.set_page_config(
    page_title="Rewriter + DUPLICATOR",
    page_icon="üåêüîÑ",
    layout="wide"
)

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è fasttext –º–æ–¥–µ–ª—ñ (lid.176.bin ‚Äî 176 –º–æ–≤)
try:
    lang_model = fasttext.load_model('lid.176.bin')
except Exception as e:
    st.warning(f"FastText –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏–ª–∞—Å—è: {e}. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ langdetect.")
    lang_model = None

# Session state
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'result' not in st.session_state:
    st.session_state.result = None

def detect_language(text: str) -> str:
    """–í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤–∏ –∑ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º –Ω—ñ–º–µ—Ü—å–∫–æ—ó"""
    text = text.replace('\n', ' ').strip()
    if len(text) < 50:
        return "de"

    # –ï–≤—Ä–∏—Å—Ç–∏–∫–∞: –Ω—ñ–º–µ—Ü—å–∫—ñ —Å–∏–º–≤–æ–ª–∏ = –Ω—ñ–º–µ—Ü—å–∫–∞
    if re.search(r'[√§√∂√º√Ñ√ñ√ú√ü]', text):
        return "de"

    if lang_model:
        pred = lang_model.predict(text, k=1)
        lang = pred[0][0].replace('__label__', '')
        prob = pred[1][0]
        # –Ø–∫—â–æ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –Ω–∏–∑—å–∫–∞ —ñ —î –Ω—ñ–º–µ—Ü—å–∫—ñ —Å–ª–æ–≤–∞ ‚Äî –Ω—ñ–º–µ—Ü—å–∫–∞
        if prob < 0.8 and any(word in text.lower() for word in ["gesund", "ern√§hrung", "wohlbefinden", "energie", "frauen", "m√§nner"]):
            return "de"
        return lang
    else:
        try:
            return detect(text)
        except LangDetectException:
            return "de"

def get_site_language(html_files: list) -> str:
    """–î–æ–º—ñ–Ω—É—é—á–∞ –º–æ–≤–∞ —Å–∞–π—Ç—É"""
    langs = []
    for path in html_files:
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            text = re.sub(r'<[^>]+>', ' ', content)[:5000]
            lang = detect_language(text)
            langs.append(lang)
        except:
            pass
    
    if not langs:
        return "de"  # –¥–µ—Ñ–æ–ª—Ç –Ω—ñ–º–µ—Ü—å–∫–∞

    most_common = Counter(langs).most_common(1)[0][0]
    lang_map = {
        'de': '–ù—ñ–º–µ—Ü—å–∫–∞',
        'uk': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞',
        'ru': '–†–æ—Å—ñ–π—Å—å–∫–∞',
        'en': '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞',
        'fr': '–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞'
    }
    return lang_map.get(most_common, "–ù—ñ–º–µ—Ü—å–∫–∞")

def rewrite_content(client, original_html: str, language: str) -> str:
    """–†–µ—Ä–∞–π—Ç —Ç—ñ–ª—å–∫–∏ –≤–∏–¥–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç—É –∑ –∂–æ—Ä—Å—Ç–∫–∏–º –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏"""
    prompt = f"""
–¢–Ü–õ–¨–ö–ò —Ä–µ—Ñ—Ä–∞–∑—É–π –≤–∏–¥–∏–º–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ –º–æ–≤—ñ '{language}' ‚Äî –∑—Ä–æ–±–∏ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º, –ø—Ä–∏—Ä–æ–¥–Ω–∏–º, –ø—Ä–∏–≤–∞–±–ª–∏–≤–∏–º.
–ó–ê–ë–û–†–û–ù–ï–ù–û –±—É–¥—å-—è–∫—ñ –∑–º—ñ–Ω–∏ –∫—Ä—ñ–º —Ç–µ–∫—Å—Ç—É:
- –ù–ï –∑–º—ñ–Ω—é–≤–∞—Ç–∏ —Ç–µ–≥–∏, –∞—Ç—Ä–∏–±—É—Ç–∏, –∫–ª–∞—Å–∏, id, name, value, placeholder, action, method, onclick, src, href
- –ù–ï –ª–∞–º–∞—Ç–∏ —Ñ–æ—Ä–º–∏, input, button, select, textarea, —Å–∫—Ä–∏–ø—Ç–∏, —Å—Ç–∏–ª—ñ, –ø–æ—Å–∏–ª–∞–Ω–Ω—è, –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- –ù–ï –¥–æ–¥–∞–≤–∞—Ç–∏/–≤–∏–¥–∞–ª—è—Ç–∏ –µ–ª–µ–º–µ–Ω—Ç–∏ HTML
- –ù–ï –∑–º—ñ–Ω—é–≤–∞—Ç–∏ JS-–∫–æ–¥, –ø–æ–¥—ñ—ó, —Å—Ç—Ä—É–∫—Ç—É—Ä—É
–ó–∞–º—ñ–Ω—é–π –¢–Ü–õ–¨–ö–ò —á–∏—Å—Ç–∏–π —Ç–µ–∫—Å—Ç –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ —Ç–µ–≥—ñ–≤ (h1-h6, p, li, span, div –∑ —Ç–µ–∫—Å—Ç–æ–º, label, option —Ç–æ—â–æ).
–ö–æ–Ω—Ç–∞–∫—Ç–∏ (–∞–¥—Ä–µ—Å–∞, —Ç–µ–ª–µ—Ñ–æ–Ω) ‚Äî –∑–∞–º—ñ–Ω–∏ –Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤—ñ –ø—Ä–∞–≤–¥–æ–ø–æ–¥—ñ–±–Ω—ñ (–∞–¥—Ä–µ—Å–∞ –≤ –£–∫—Ä–∞—ó–Ω—ñ, +380 –Ω–æ–º–µ—Ä).
–Ø–∫—â–æ –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤ –Ω–µ –±—É–ª–æ ‚Äî –Ω–µ –¥–æ–¥–∞–≤–∞–π.
–ü–æ–≤–µ—Ä—Ç–∞–π –¢–Ü–õ–¨–ö–ò –ø–æ–≤–Ω–∏–π –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π HTML –∑ –∑–∞–º—ñ–Ω–µ–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω—å, –±–µ–∑ ```html —á–∏ markdown.
–û—Ä–∏–≥—ñ–Ω–∞–ª:
{original_html}
"""

    try:
        resp = client.chat.completions.create(
            model="grok-code-fast-1",  # —à–≤–∏–¥–∫–∞ –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—Å—Ç—É —Ç–∞ –∫–æ–¥—É
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=8192,
            timeout=600
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"–ü–æ–º–∏–ª–∫–∞ —Ä–µ—Ä–∞–π—Ç—É: {str(e)}. –ó–∞–ª–∏—à–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª.")
        return original_html

st.title("üåê Rewriter + DUPLICATOR ‚Äî –†–µ—Ä–∞–π—Ç —Ç–µ–∫—Å—Ç—É + –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è")

with st.expander("‚ÑπÔ∏è –Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏", expanded=True):
    st.markdown("""
    1. –í–≤–µ–¥–∏ xAI API Key  
    2. –ó–∞–≤–∞–Ω—Ç–∞–∂ ZIP/RAR –∞—Ä—Ö—ñ–≤(–∏) —Å–∞–π—Ç—É  
    3. –û–±–µ—Ä–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ø—ñ–π —ñ –¥–æ–º–µ–Ω–Ω—É –∑–æ–Ω—É  
    4. –ù–∞—Ç–∏—Å–Ω–∏ –∫–Ω–æ–ø–∫—É ‚Äî –æ—Ç—Ä–∏–º–∞–π –∞—Ä—Ö—ñ–≤–∏ –∑ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º —ñ –Ω–æ–≤–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏
    """)

api_key = st.text_input("xAI API Key", type="password")

col1, col2 = st.columns([2, 1])

with col1:
    uploaded_files = st.file_uploader(
        "–ê—Ä—Ö—ñ–≤–∏ —Å–∞–π—Ç—ñ–≤ (ZIP/RAR)",
        type=['zip', 'rar'],
        accept_multiple_files=True
    )

with col2:
    domain_zone = st.radio("–î–æ–º–µ–Ω–Ω–∞ –∑–æ–Ω–∞:", ['.com', '.info'], horizontal=True)
    copies_count = st.number_input("–ö–æ–ø—ñ–π –Ω–∞ –∞—Ä—Ö—ñ–≤:", min_value=1, max_value=20, value=5)

if uploaded_files and api_key:
    if st.button("üöÄ –°—Ç–≤–æ—Ä–∏—Ç–∏ 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –∑ —Ä–µ—Ä–∞–π—Ç–æ–º", type="primary"):
        client = OpenAI(api_key=api_key, base_url="https://api.x.ai/v1", timeout=600)

        temp_input = tempfile.mkdtemp()
        temp_rewritten = tempfile.mkdtemp()
        temp_clones = tempfile.mkdtemp()

        progress = st.progress(0)
        status = st.empty()

        # 1. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞—Ä—Ö—ñ–≤—ñ–≤
        status.text("–ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞—Ä—Ö—ñ–≤–∏...")
        archive_paths = []
        for i, f in enumerate(uploaded_files):
            path = os.path.join(temp_input, f.name)
            with open(path, 'wb') as out:
                out.write(f.getbuffer())
            archive_paths.append(path)
            progress.progress((i+1)/len(uploaded_files) * 0.1)

        # 2. –†–æ–∑–ø–∞–∫–æ–≤–∫–∞ —Ç–∞ —Ä–µ—Ä–∞–π—Ç
        status.text("–†–æ–∑–ø–∞–∫–æ–≤—É—î–º–æ —Ç–∞ —Ä–µ—Ä–∞–π—Ç–∏–º–æ —Ç–µ–∫—Å—Ç...")
        all_rewritten_dirs = []
        for arch_idx, arch in enumerate(archive_paths):
            extract_dir = os.path.join(temp_rewritten, f"arch_{arch_idx}")
            os.makedirs(extract_dir, exist_ok=True)
            try:
                with zipfile.ZipFile(arch, 'r') as z:
                    z.extractall(extract_dir)
            except:
                st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞–∫—É–≤–∞—Ç–∏ {os.path.basename(arch)}")
                continue

            html_files = [os.path.join(root, f) for root, _, fs in os.walk(extract_dir) for f in fs if f.lower().endswith('.html')]

            lang = get_site_language(html_files)
            st.info(f"–ú–æ–≤–∞ –∞—Ä—Ö—ñ–≤—É {os.path.basename(arch)}: {lang}")

            for html in html_files:
                with open(html, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                new_content = rewrite_content(client, content, lang)
                with open(html, 'w', encoding='utf-8') as f:
                    f.write(new_content)

            all_rewritten_dirs.append(extract_dir)
            progress.progress(0.1 + (arch_idx+1)/len(archive_paths) * 0.4)

        # 3. –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è (—Å—Ç–≤–æ—Ä–µ–Ω–Ω—è 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤)
        status.text("–°—Ç–≤–æ—Ä—é—î–º–æ 5 –∫–æ–ø—ñ–π –∑ –Ω–æ–≤–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏...")
        master_zip_path = os.path.join(temp_clones, "duplicates.zip")
        with zipfile.ZipFile(master_zip_path, 'w', zipfile.ZIP_DEFLATED) as master_zip:
            for var_num in range(1, 6):
                for dir_idx, rewritten_dir in enumerate(all_rewritten_dirs):
                    new_dir = os.path.join(temp_clones, f"var_{var_num}_arch_{dir_idx}")
                    shutil.copytree(rewritten_dir, new_dir, dirs_exist_ok=True)
                    # –¢—É—Ç –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –∑–∞–º—ñ–Ω—É –¥–æ–º–µ–Ω—ñ–≤ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, —Ñ—É–Ω–∫—Ü—ñ—é replace_domain_in_dir)
                    # –ü—Ä–∏–∫–ª–∞–¥: replace_domain_in_dir(new_dir, "old.com", f"newdomain{var_num}{domain_zone}")

                    for root, _, files in os.walk(new_dir):
                        for file in files:
                            full = os.path.join(root, file)
                            arc = os.path.relpath(full, temp_clones)
                            master_zip.write(full, arc)

        st.session_state.result = {'success': True, 'master_archive_path': master_zip_path}
        st.session_state.processed = True
        st.rerun()

else:
    st.warning("–í–≤–µ–¥–∏ –∫–ª—é—á —ñ –∑–∞–≤–∞–Ω—Ç–∞–∂ –∞—Ä—Ö—ñ–≤–∏")

if st.session_state.processed and st.session_state.result:
    st.success("–ì–æ—Ç–æ–≤–æ! 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ —Å—Ç–≤–æ—Ä–µ–Ω–æ.")
    with open(st.session_state.result['master_archive_path'], 'rb') as f:
        data = f.read()
    st.download_button(
        label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç–∏ –≥–æ–ª–æ–≤–Ω–∏–π –∞—Ä—Ö—ñ–≤ (–≤—Å—ñ 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –∑ —Ä–µ—Ä–∞–π—Ç–æ–º)",
        data=data,
        file_name="rewritten_duplicates.zip",
        mime="application/zip"
    )
