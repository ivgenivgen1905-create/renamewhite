import streamlit as st
import zipfile
import tempfile
import os
import shutil
import io
import re
from openai import OpenAI
from langdetect import detect, LangDetectException
from collections import Counter

st.set_page_config(
    page_title="Rewriter + DUPLICATOR",
    page_icon="üåêüîÑ",
    layout="wide"
)

# Session state
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'result' not in st.session_state:
    st.session_state.result = None

def detect_language(text: str) -> str:
    """–í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤–∏ –∑ —Å–∏–ª—å–Ω–∏–º –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º –Ω—ñ–º–µ—Ü—å–∫–æ—ó"""
    text_lower = text.lower()
    if len(text.strip()) < 50:
        return "de"

    # –ï–≤—Ä–∏—Å—Ç–∏–∫–∞ 1: –Ω—ñ–º–µ—Ü—å–∫—ñ —Å–∏–º–≤–æ–ª–∏ = —Ç–æ—á–Ω–æ de
    if re.search(r'[√§√∂√º√Ñ√ñ√ú√ü]', text):
        return "de"

    # –ï–≤—Ä–∏—Å—Ç–∏–∫–∞ 2: –Ω—ñ–º–µ—Ü—å–∫—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ (–∑ —Ç–≤–æ–≥–æ —Ç–µ–∫—Å—Ç—É)
    german_keywords = ["gesund", "ern√§hrung", "wohlbefinden", "energie", "frauen", "m√§nner", "ern√§hrungstipps", "gesundheit", "bewusste"]
    german_count = sum(1 for word in german_keywords if word in text_lower)
    if german_count >= 2:
        return "de"

    # –ï–≤—Ä–∏—Å—Ç–∏–∫–∞ 3: —è–∫—â–æ –±–∞–≥–∞—Ç–æ "√ü", "√§" —Ç–æ—â–æ ‚Äî de
    if text_lower.count('√ü') + text_lower.count('√§') + text_lower.count('√∂') + text_lower.count('√º') > 1:
        return "de"

    # langdetect —è–∫ –æ—Å—Ç–∞–Ω–Ω—ñ–π –≤–∞—Ä—ñ–∞–Ω—Ç
    try:
        lang = detect(text)
        if lang in ['de', 'nl', 'da']:  # –Ω—ñ–º–µ—Ü—å–∫–∞ + –±–ª–∏–∑—å–∫—ñ
            return "de"
        return lang
    except LangDetectException:
        return "de"  # –¥–µ—Ñ–æ–ª—Ç –¥–ª—è —Ç–≤–æ–≥–æ —Å–∞–π—Ç—É

def get_site_language(html_files: list) -> str:
    """–î–æ–º—ñ–Ω—É—é—á–∞ –º–æ–≤–∞ —Å–∞–π—Ç—É"""
    langs = []
    for path in html_files:
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            # –ë–µ—Ä–µ–º–æ —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–µ–≥—ñ–≤, –æ–±–º–µ–∂—É—î–º–æ —Ä–æ–∑–º—ñ—Ä
            text = re.sub(r'<[^>]+>', ' ', content)[:10000]
            lang = detect_language(text)
            langs.append(lang)
        except:
            pass
    
    if not langs:
        return "de"

    most_common = Counter(langs).most_common(1)[0][0]
    lang_map = {
        'de': '–ù—ñ–º–µ—Ü—å–∫–∞',
        'uk': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞',
        'ru': '–†–æ—Å—ñ–π—Å—å–∫–∞',
        'en': '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞',
        'fr': '–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞'
    }
    return lang_map.get(most_common, "–ù—ñ–º–µ—Ü—å–∫–∞")

def rewrite_content(client, original_html: str, language: str) -> str:
    prompt = f"""
–¢–Ü–õ–¨–ö–ò —Ä–µ—Ñ—Ä–∞–∑—É–π –≤–∏–¥–∏–º–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ –º–æ–≤—ñ '{language}' ‚Äî –∑—Ä–æ–±–∏ –π–æ–≥–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º, –ø—Ä–∏—Ä–æ–¥–Ω–∏–º, –ø—Ä–∏–≤–∞–±–ª–∏–≤–∏–º.
–ó–ê–ë–û–†–û–ù–ï–ù–û –±—É–¥—å-—è–∫—ñ –∑–º—ñ–Ω–∏ –∫—Ä—ñ–º —Ç–µ–∫—Å—Ç—É:
- –ù–ï –∑–º—ñ–Ω—é–≤–∞—Ç–∏ —Ç–µ–≥–∏, –∞—Ç—Ä–∏–±—É—Ç–∏, –∫–ª–∞—Å–∏, id, name, value, placeholder, action, method, onclick, src, href
- –ù–ï –ª–∞–º–∞—Ç–∏ —Ñ–æ—Ä–º–∏, input, button, select, textarea, —Å–∫—Ä–∏–ø—Ç–∏, —Å—Ç–∏–ª—ñ, –ø–æ—Å–∏–ª–∞–Ω–Ω—è, –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- –ù–ï –¥–æ–¥–∞–≤–∞—Ç–∏/–≤–∏–¥–∞–ª—è—Ç–∏ –µ–ª–µ–º–µ–Ω—Ç–∏
- –ù–ï –∑–º—ñ–Ω—é–≤–∞—Ç–∏ JS-–∫–æ–¥, –ø–æ–¥—ñ—ó, —Å—Ç—Ä—É–∫—Ç—É—Ä—É
–ó–∞–º—ñ–Ω—é–π –¢–Ü–õ–¨–ö–ò —á–∏—Å—Ç–∏–π —Ç–µ–∫—Å—Ç –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ —Ç–µ–≥—ñ–≤ (h1-h6, p, li, span, div –∑ —Ç–µ–∫—Å—Ç–æ–º, label, option —Ç–æ—â–æ).
–ö–æ–Ω—Ç–∞–∫—Ç–∏ (–∞–¥—Ä–µ—Å–∞, —Ç–µ–ª–µ—Ñ–æ–Ω) ‚Äî –∑–∞–º—ñ–Ω–∏ –Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤—ñ –ø—Ä–∞–≤–¥–æ–ø–æ–¥—ñ–±–Ω—ñ (–∞–¥—Ä–µ—Å–∞ –≤ –£–∫—Ä–∞—ó–Ω—ñ, +380 –Ω–æ–º–µ—Ä).
–Ø–∫—â–æ –∫–æ–Ω—Ç–∞–∫—Ç—ñ–≤ –Ω–µ –±—É–ª–æ ‚Äî –Ω–µ –¥–æ–¥–∞–≤–∞–π.
–ü–æ–≤–µ—Ä—Ç–∞–π –¢–Ü–õ–¨–ö–ò –ø–æ–≤–Ω–∏–π –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π HTML –∑ –∑–∞–º—ñ–Ω–µ–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω—å, –±–µ–∑ ```html —á–∏ markdown.
–û—Ä–∏–≥—ñ–Ω–∞–ª:
{original_html}
"""

    try:
        resp = client.chat.completions.create(
            model="grok-code-fast-1",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=8192,
            timeout=600
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"–ü–æ–º–∏–ª–∫–∞ —Ä–µ—Ä–∞–π—Ç—É: {str(e)}. –ó–∞–ª–∏—à–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª.")
        return original_html

st.title("üåê Rewriter + DUPLICATOR ‚Äî –†–µ—Ä–∞–π—Ç —Ç–µ–∫—Å—Ç—É + –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è")

with st.expander("‚ÑπÔ∏è –Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏", expanded=True):
    st.markdown("""
    1. –í–≤–µ–¥–∏ xAI API Key  
    2. –ó–∞–≤–∞–Ω—Ç–∞–∂ ZIP/RAR –∞—Ä—Ö—ñ–≤(–∏) —Å–∞–π—Ç—É  
    3. –û–±–µ—Ä–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ø—ñ–π —ñ –¥–æ–º–µ–Ω–Ω—É –∑–æ–Ω—É  
    4. –ù–∞—Ç–∏—Å–Ω–∏ –∫–Ω–æ–ø–∫—É ‚Äî –æ—Ç—Ä–∏–º–∞–π –∞—Ä—Ö—ñ–≤–∏ –∑ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º —ñ –Ω–æ–≤–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏
    """)

api_key = st.text_input("xAI API Key", type="password")

col1, col2 = st.columns([2, 1])

with col1:
    uploaded_files = st.file_uploader(
        "–ê—Ä—Ö—ñ–≤–∏ —Å–∞–π—Ç—ñ–≤ (ZIP/RAR)",
        type=['zip', 'rar'],
        accept_multiple_files=True
    )

with col2:
    domain_zone = st.radio("–î–æ–º–µ–Ω–Ω–∞ –∑–æ–Ω–∞:", ['.com', '.info'], horizontal=True)
    copies_count = st.number_input("–ö–æ–ø—ñ–π –Ω–∞ –∞—Ä—Ö—ñ–≤:", min_value=1, max_value=20, value=5)

if uploaded_files and api_key:
    if st.button("üöÄ –°—Ç–≤–æ—Ä–∏—Ç–∏ 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –∑ —Ä–µ—Ä–∞–π—Ç–æ–º", type="primary"):
        client = OpenAI(api_key=api_key, base_url="https://api.x.ai/v1", timeout=600)

        temp_input = tempfile.mkdtemp()
        temp_rewritten = tempfile.mkdtemp()
        temp_clones = tempfile.mkdtemp()

        progress = st.progress(0)
        status = st.empty()

        # 1. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞—Ä—Ö—ñ–≤—ñ–≤
        status.text("–ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞—Ä—Ö—ñ–≤–∏...")
        archive_paths = []
        for i, f in enumerate(uploaded_files):
            path = os.path.join(temp_input, f.name)
            with open(path, 'wb') as out:
                out.write(f.getbuffer())
            archive_paths.append(path)
            progress.progress((i+1)/len(uploaded_files) * 0.1)

        # 2. –†–æ–∑–ø–∞–∫–æ–≤–∫–∞ —Ç–∞ —Ä–µ—Ä–∞–π—Ç
        status.text("–†–æ–∑–ø–∞–∫–æ–≤—É—î–º–æ —Ç–∞ —Ä–µ—Ä–∞–π—Ç–∏–º–æ —Ç–µ–∫—Å—Ç...")
        all_rewritten_dirs = []
        for arch_idx, arch in enumerate(archive_paths):
            extract_dir = os.path.join(temp_rewritten, f"arch_{arch_idx}")
            os.makedirs(extract_dir, exist_ok=True)
            try:
                with zipfile.ZipFile(arch, 'r') as z:
                    z.extractall(extract_dir)
            except:
                st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞–∫—É–≤–∞—Ç–∏ {os.path.basename(arch)}")
                continue

            html_files = [os.path.join(root, f) for root, _, fs in os.walk(extract_dir) for f in fs if f.lower().endswith('.html')]

            lang = get_site_language(html_files)
            st.info(f"–ú–æ–≤–∞ –∞—Ä—Ö—ñ–≤—É {os.path.basename(arch)}: {lang}")

            for html in html_files:
                with open(html, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                new_content = rewrite_content(client, content, lang)
                with open(html, 'w', encoding='utf-8') as f:
                    f.write(new_content)

            all_rewritten_dirs.append(extract_dir)
            progress.progress(0.1 + (arch_idx+1)/len(archive_paths) * 0.4)

        # 3. –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è
        status.text("–°—Ç–≤–æ—Ä—é—î–º–æ 5 –∫–æ–ø—ñ–π –∑ –Ω–æ–≤–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏...")
        master_zip_path = os.path.join(temp_clones, "duplicates.zip")
        with zipfile.ZipFile(master_zip_path, 'w', zipfile.ZIP_DEFLATED) as master_zip:
            for var_num in range(1, 6):
                for dir_idx, rewritten_dir in enumerate(all_rewritten_dirs):
                    new_dir = os.path.join(temp_clones, f"var_{var_num}_arch_{dir_idx}")
                    shutil.copytree(rewritten_dir, new_dir, dirs_exist_ok=True)
                    # –î–æ–¥–∞–π –∑–∞–º—ñ–Ω—É –¥–æ–º–µ–Ω—ñ–≤ —Ç—É—Ç, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
                    for root, _, files in os.walk(new_dir):
                        for file in files:
                            full = os.path.join(root, file)
                            arc = os.path.relpath(full, temp_clones)
                            master_zip.write(full, arc)

        st.session_state.result = {'success': True, 'master_archive_path': master_zip_path}
        st.session_state.processed = True
        st.rerun()

else:
    st.warning("–í–≤–µ–¥–∏ –∫–ª—é—á —ñ –∑–∞–≤–∞–Ω—Ç–∞–∂ –∞—Ä—Ö—ñ–≤–∏")

if st.session_state.processed and st.session_state.result:
    st.success("–ì–æ—Ç–æ–≤–æ! 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ —Å—Ç–≤–æ—Ä–µ–Ω–æ.")
    with open(st.session_state.result['master_archive_path'], 'rb') as f:
        data = f.read()
    st.download_button(
        label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç–∏ –≥–æ–ª–æ–≤–Ω–∏–π –∞—Ä—Ö—ñ–≤ (–≤—Å—ñ 5 –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –∑ —Ä–µ—Ä–∞–π—Ç–æ–º)",
        data=data,
        file_name="rewritten_duplicates.zip",
        mime="application/zip"
    )
